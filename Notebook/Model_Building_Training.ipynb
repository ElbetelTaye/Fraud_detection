{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import torch\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/24 14:56:45 WARNING mlflow.utils.autologging_utils: MLflow pytorch autologging is known to be compatible with 1.9.0 <= torch <= 2.4.1, but the installed version is 2.5.0. If you encounter errors during autologging, try upgrading / downgrading torch to a compatible version, or try upgrading MLflow.\n"
     ]
    }
   ],
   "source": [
    "# Enable MLflow autologging \n",
    "mlflow.pytorch.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the merged fraud data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchase_value</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "      <th>time_diff</th>\n",
       "      <th>transaction_count</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>purchase_value_scaled</th>\n",
       "      <th>source_Direct</th>\n",
       "      <th>...</th>\n",
       "      <th>country_United States</th>\n",
       "      <th>country_Uruguay</th>\n",
       "      <th>country_Uzbekistan</th>\n",
       "      <th>country_Vanuatu</th>\n",
       "      <th>country_Venezuela</th>\n",
       "      <th>country_Viet Nam</th>\n",
       "      <th>country_Virgin Islands (U.S.)</th>\n",
       "      <th>country_Yemen</th>\n",
       "      <th>country_Zambia</th>\n",
       "      <th>country_Zimbabwe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1008.948611</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.549607</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>342.121389</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.197335</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>554.870556</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>0.385831</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>2122.471389</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>0.986342</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>2847.105278</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.767974</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 195 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   purchase_value  sex  age  class    time_diff  transaction_count  \\\n",
       "0              47    0   30      0  1008.948611                  1   \n",
       "1              15    0   34      0   342.121389                  1   \n",
       "2              44    1   29      0   554.870556                  1   \n",
       "3              55    0   30      0  2122.471389                  1   \n",
       "4              51    0   37      0  2847.105278                  1   \n",
       "\n",
       "   hour_of_day  day_of_week  purchase_value_scaled  source_Direct  ...  \\\n",
       "0            3            6               0.549607          False  ...   \n",
       "1           20            2              -1.197335          False  ...   \n",
       "2           23            5               0.385831          False  ...   \n",
       "3           16            5               0.986342           True  ...   \n",
       "4            4            1               0.767974          False  ...   \n",
       "\n",
       "   country_United States  country_Uruguay  country_Uzbekistan  \\\n",
       "0                  False            False               False   \n",
       "1                  False            False               False   \n",
       "2                  False            False               False   \n",
       "3                  False            False               False   \n",
       "4                  False            False               False   \n",
       "\n",
       "   country_Vanuatu  country_Venezuela  country_Viet Nam  \\\n",
       "0            False              False             False   \n",
       "1            False              False             False   \n",
       "2            False              False             False   \n",
       "3            False              False             False   \n",
       "4            False              False             False   \n",
       "\n",
       "   country_Virgin Islands (U.S.)  country_Yemen  country_Zambia  \\\n",
       "0                          False          False           False   \n",
       "1                          False          False           False   \n",
       "2                          False          False           False   \n",
       "3                          False          False           False   \n",
       "4                          False          False           False   \n",
       "\n",
       "   country_Zimbabwe  \n",
       "0             False  \n",
       "1             False  \n",
       "2             False  \n",
       "3             False  \n",
       "4             False  \n",
       "\n",
       "[5 rows x 195 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "credit data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "      <th>time_in_days</th>\n",
       "      <th>Amount_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.244200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.342584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>1.158900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.139886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>-0.073813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V23       V24       V25       V26       V27  \\\n",
       "0  0.098698  0.363787  ... -0.110474  0.066928  0.128539 -0.189115  0.133558   \n",
       "1  0.085102 -0.255425  ...  0.101288 -0.339846  0.167170  0.125895 -0.008983   \n",
       "2  0.247676 -1.514654  ...  0.909412 -0.689281 -0.327642 -0.139097 -0.055353   \n",
       "3  0.377436 -1.387024  ... -0.190321 -1.175575  0.647376 -0.221929  0.062723   \n",
       "4 -0.270533  0.817739  ... -0.137458  0.141267 -0.206010  0.502292  0.219422   \n",
       "\n",
       "        V28  Amount  Class  time_in_days  Amount_scaled  \n",
       "0 -0.021053  149.62      0      0.000000       0.244200  \n",
       "1  0.014724    2.69      0      0.000000      -0.342584  \n",
       "2 -0.059752  378.66      0      0.000012       1.158900  \n",
       "3  0.061458  123.50      0      0.000012       0.139886  \n",
       "4  0.215153   69.99      0      0.000023      -0.073813  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the cleaned datasets (from Task 1)\n",
    "fraud_data = pd.read_csv('C:/Users/elbet/OneDrive/Desktop/Ten/week8&9/github/Fraud_detection/cleaned_data/merged_data.csv')\n",
    "creditcard_data = pd.read_csv('C:/Users/elbet/OneDrive/Desktop/Ten/week8&9/github/Fraud_detection/cleaned_data/Preprocessed_Creditcard_Data.csv')\n",
    "\n",
    "# Drop unnecessary columns for training\n",
    "fraud_data = fraud_data.drop(columns=['signup_time', 'purchase_time', 'user_id', 'device_id', \n",
    "                                      'ip_address', 'lower_bound_ip_address', 'upper_bound_ip_address'], errors='ignore')\n",
    "\n",
    "print('the merged fraud data')\n",
    "display(fraud_data.head())\n",
    "\n",
    "print('credit data')\n",
    "\n",
    "display(creditcard_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and targets for Fraud Data\n",
    "X_fraud = fraud_data.drop(columns=['class'])  # Feature set\n",
    "y_fraud = fraud_data['class']  # Target\n",
    "\n",
    "# Separate features and targets for Credit Card Data\n",
    "X_credit = creditcard_data.drop(columns=['Class'])  # Feature set\n",
    "y_credit = creditcard_data['Class']  # Target\n",
    "\n",
    "# Apply SMOTE to balance the dataset\n",
    "smote = SMOTE(random_state=42)\n",
    "X_fraud, y_fraud = smote.fit_resample(X_fraud, y_fraud)\n",
    "X_credit, y_credit = smote.fit_resample(X_credit, y_credit)\n",
    "\n",
    "# Train-Test Split for both datasets\n",
    "X_fraud_train, X_fraud_test, y_fraud_train, y_fraud_test = train_test_split(X_fraud, y_fraud, test_size=0.2, random_state=42)\n",
    "X_credit_train, X_credit_test, y_credit_train, y_credit_test = train_test_split(X_credit, y_credit, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize the data (Standard Scaling)\n",
    "scaler = StandardScaler()\n",
    "X_fraud_train = scaler.fit_transform(X_fraud_train)\n",
    "X_fraud_test = scaler.transform(X_fraud_test)\n",
    "X_credit_train = scaler.fit_transform(X_credit_train)\n",
    "X_credit_test = scaler.transform(X_credit_test)\n",
    "\n",
    "# Convert the datasets into PyTorch tensors\n",
    "X_fraud_train_tensor = torch.tensor(X_fraud_train, dtype=torch.float32)\n",
    "y_fraud_train_tensor = torch.tensor(y_fraud_train.values, dtype=torch.float32)\n",
    "X_fraud_test_tensor = torch.tensor(X_fraud_test, dtype=torch.float32)\n",
    "y_fraud_test_tensor = torch.tensor(y_fraud_test.values, dtype=torch.float32)\n",
    "\n",
    "X_credit_train_tensor = torch.tensor(X_credit_train, dtype=torch.float32)\n",
    "y_credit_train_tensor = torch.tensor(y_credit_train.values, dtype=torch.float32)\n",
    "X_credit_test_tensor = torch.tensor(X_credit_test, dtype=torch.float32)\n",
    "y_credit_test_tensor = torch.tensor(y_credit_test.values, dtype=torch.float32)\n",
    "\n",
    "# DataLoader for batching\n",
    "batch_size = 16\n",
    "train_loader_fraud = torch.utils.data.DataLoader(TensorDataset(X_fraud_train_tensor, y_fraud_train_tensor), batch_size=batch_size, shuffle=True)\n",
    "test_loader_fraud = torch.utils.data.DataLoader(TensorDataset(X_fraud_test_tensor, y_fraud_test_tensor), batch_size=batch_size)\n",
    "\n",
    "train_loader_credit = torch.utils.data.DataLoader(TensorDataset(X_credit_train_tensor, y_credit_train_tensor), batch_size=batch_size, shuffle=True)\n",
    "test_loader_credit = torch.utils.data.DataLoader(TensorDataset(X_credit_test_tensor, y_credit_test_tensor), batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping mechanism\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = loss\n",
    "        elif loss > self.best_loss + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = loss\n",
    "            self.counter = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definitions (MLP, CNN, RNN, LSTM)\n",
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLPModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * input_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Add channel dimension\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size=32, batch_first=True)\n",
    "        self.fc = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Add sequence dimension\n",
    "        h0 = torch.zeros(1, x.size(0), 32)  # Initial hidden state\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = torch.sigmoid(self.fc(out[:, -1, :]))\n",
    "        return out\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size=32, batch_first=True)\n",
    "        self.fc = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Add sequence dimension\n",
    "        h0 = torch.zeros(1, x.size(0), 32)  # Initial hidden state\n",
    "        c0 = torch.zeros(1, x.size(0), 32)  # Initial cell state\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = torch.sigmoid(self.fc(out[:, -1, :]))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop with MLflow tracking\n",
    "def train_model(model, train_loader, optimizer, criterion, num_epochs=10, patience=5, model_name=\"model\"):\n",
    "    early_stopper = EarlyStopping(patience=patience)\n",
    "    model.train()\n",
    "    \n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        for epoch in range(num_epochs):\n",
    "            total_loss = 0\n",
    "            for X_batch, y_batch in train_loader:\n",
    "                optimizer.zero_grad()  # Clear gradients\n",
    "                y_pred = model(X_batch).squeeze()  # Forward pass\n",
    "                loss = criterion(y_pred, y_batch)  # Compute loss\n",
    "                loss.backward()  # Backward pass\n",
    "                optimizer.step()  # Update weights\n",
    "                total_loss += loss.item()\n",
    "\n",
    "            avg_loss = total_loss / len(train_loader)\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
    "            \n",
    "            # Log loss for each epoch\n",
    "            mlflow.log_metric('loss', avg_loss, step=epoch)\n",
    "\n",
    "            # Early stopping\n",
    "            early_stopper(avg_loss)\n",
    "            if early_stopper.early_stop:\n",
    "                print(\"Early stopping triggered!\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "# Updated PyTorch model evaluation function\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()  # Set to evaluation mode\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            y_pred = model(X_batch).squeeze()\n",
    "            preds = (y_pred > 0.5).float()  # Convert probabilities to 0/1\n",
    "            all_preds.extend(preds.numpy())\n",
    "            all_labels.extend(y_batch.numpy())\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='macro')\n",
    "    recall = recall_score(all_labels, all_preds, average='macro')\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models for both fraud and credit datasets\n",
    "input_size_fraud = X_fraud_train.shape[1]\n",
    "input_size_credit = X_credit_train.shape[1]\n",
    "\n",
    "mlp_model_fraud = MLPModel(input_size_fraud)\n",
    "cnn_model_fraud = CNNModel(input_size_fraud)\n",
    "rnn_model_fraud = RNNModel(input_size_fraud)\n",
    "lstm_model_fraud = LSTMModel(input_size_fraud)\n",
    "\n",
    "mlp_model_credit = MLPModel(input_size_credit)\n",
    "cnn_model_credit = CNNModel(input_size_credit)\n",
    "rnn_model_credit = RNNModel(input_size_credit)\n",
    "lstm_model_credit = LSTMModel(input_size_credit)\n",
    "\n",
    "# Set loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Train and evaluate each model for both fraud and credit data\n",
    "models = {\n",
    "    \"MLP_Fraud\": mlp_model_fraud,\n",
    "    \"CNN_Fraud\": cnn_model_fraud,\n",
    "    \"RNN_Fraud\": rnn_model_fraud,\n",
    "    \"LSTM_Fraud\": lstm_model_fraud,\n",
    "    \"MLP_Credit\": mlp_model_credit,\n",
    "    \"CNN_Credit\": cnn_model_credit,\n",
    "    \"RNN_Credit\": rnn_model_credit,\n",
    "    \"LSTM_Credit\": lstm_model_credit,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the models\n",
    "save_folder = 'C:/Users/elbet/OneDrive/Desktop/Ten/week8&9/github/Fraud_detection/DL_saved_models'\n",
    "os.makedirs(save_folder, exist_ok=True) \n",
    "\n",
    "# Function to save PyTorch models\n",
    "def save_pytorch_model(model, model_name):\n",
    "    save_path = os.path.join(save_folder, f'{model_name}.pt')\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f'{model_name} saved at {save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training MLP_Fraud...\n",
      "Epoch [1/10], Loss: 0.2758\n",
      "Epoch [2/10], Loss: 0.2280\n",
      "Epoch [3/10], Loss: 0.2160\n",
      "Epoch [4/10], Loss: 0.2159\n",
      "Epoch [5/10], Loss: 0.2126\n",
      "Epoch [6/10], Loss: 0.2002\n",
      "Epoch [7/10], Loss: 0.1962\n",
      "Epoch [8/10], Loss: 0.1919\n",
      "Epoch [9/10], Loss: 0.1906\n",
      "Epoch [10/10], Loss: 0.1914\n",
      "Evaluating MLP_Fraud...\n",
      "Accuracy: 0.9361\n",
      "Precision: 0.9386\n",
      "Recall: 0.9365\n",
      "F1 Score: 0.9361\n",
      "MLP_Fraud saved at C:/Users/elbet/OneDrive/Desktop/Ten/week8&9/github/Fraud_detection/DL_saved_models\\MLP_Fraud.pt\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Training CNN_Fraud...\n",
      "Epoch [1/10], Loss: 0.2660\n",
      "Epoch [2/10], Loss: 0.2022\n",
      "Epoch [3/10], Loss: 0.1937\n",
      "Epoch [4/10], Loss: 0.1895\n",
      "Epoch [5/10], Loss: 0.1865\n",
      "Epoch [6/10], Loss: 0.1853\n",
      "Epoch [7/10], Loss: 0.1849\n",
      "Epoch [8/10], Loss: 0.1831\n",
      "Epoch [9/10], Loss: 0.1828\n",
      "Epoch [10/10], Loss: 0.1824\n",
      "Evaluating CNN_Fraud...\n",
      "Accuracy: 0.9411\n",
      "Precision: 0.9454\n",
      "Recall: 0.9416\n",
      "F1 Score: 0.9410\n",
      "CNN_Fraud saved at C:/Users/elbet/OneDrive/Desktop/Ten/week8&9/github/Fraud_detection/DL_saved_models\\CNN_Fraud.pt\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Training RNN_Fraud...\n",
      "Epoch [1/10], Loss: 0.3191\n",
      "Epoch [2/10], Loss: 0.2350\n",
      "Epoch [3/10], Loss: 0.2198\n",
      "Epoch [4/10], Loss: 0.2122\n",
      "Epoch [5/10], Loss: 0.2070\n",
      "Epoch [6/10], Loss: 0.2031\n",
      "Epoch [7/10], Loss: 0.1998\n",
      "Epoch [8/10], Loss: 0.1978\n",
      "Epoch [9/10], Loss: 0.1959\n",
      "Epoch [10/10], Loss: 0.1942\n",
      "Evaluating RNN_Fraud...\n",
      "Accuracy: 0.9346\n",
      "Precision: 0.9371\n",
      "Recall: 0.9349\n",
      "F1 Score: 0.9345\n",
      "RNN_Fraud saved at C:/Users/elbet/OneDrive/Desktop/Ten/week8&9/github/Fraud_detection/DL_saved_models\\RNN_Fraud.pt\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Training LSTM_Fraud...\n",
      "Epoch [1/10], Loss: 0.2870\n",
      "Epoch [2/10], Loss: 0.2254\n",
      "Epoch [3/10], Loss: 0.2124\n",
      "Epoch [4/10], Loss: 0.2046\n",
      "Epoch [5/10], Loss: 0.1996\n",
      "Epoch [6/10], Loss: 0.1953\n",
      "Epoch [7/10], Loss: 0.1920\n",
      "Epoch [8/10], Loss: 0.1890\n",
      "Epoch [9/10], Loss: 0.1866\n",
      "Epoch [10/10], Loss: 0.1845\n",
      "Evaluating LSTM_Fraud...\n",
      "Accuracy: 0.9321\n",
      "Precision: 0.9337\n",
      "Recall: 0.9323\n",
      "F1 Score: 0.9320\n",
      "LSTM_Fraud saved at C:/Users/elbet/OneDrive/Desktop/Ten/week8&9/github/Fraud_detection/DL_saved_models\\LSTM_Fraud.pt\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Training MLP_Credit...\n",
      "Epoch [1/10], Loss: 0.0319\n",
      "Epoch [2/10], Loss: 0.0164\n",
      "Epoch [3/10], Loss: 0.0146\n",
      "Epoch [4/10], Loss: 0.0133\n",
      "Epoch [5/10], Loss: 0.0131\n",
      "Epoch [6/10], Loss: 0.0129\n",
      "Epoch [7/10], Loss: 0.0122\n",
      "Epoch [8/10], Loss: 0.0128\n",
      "Epoch [9/10], Loss: 0.0123\n",
      "Epoch [10/10], Loss: 0.0120\n",
      "Evaluating MLP_Credit...\n",
      "Accuracy: 0.9989\n",
      "Precision: 0.9989\n",
      "Recall: 0.9989\n",
      "F1 Score: 0.9989\n",
      "MLP_Credit saved at C:/Users/elbet/OneDrive/Desktop/Ten/week8&9/github/Fraud_detection/DL_saved_models\\MLP_Credit.pt\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Training CNN_Credit...\n",
      "Epoch [1/10], Loss: 0.0431\n",
      "Epoch [2/10], Loss: 0.0233\n",
      "Epoch [3/10], Loss: 0.0183\n",
      "Epoch [4/10], Loss: 0.0167\n",
      "Epoch [5/10], Loss: 0.0152\n",
      "Epoch [6/10], Loss: 0.0147\n",
      "Epoch [7/10], Loss: 0.0143\n",
      "Epoch [8/10], Loss: 0.0137\n",
      "Epoch [9/10], Loss: 0.0140\n",
      "Epoch [10/10], Loss: 0.0136\n",
      "Evaluating CNN_Credit...\n",
      "Accuracy: 0.9983\n",
      "Precision: 0.9983\n",
      "Recall: 0.9983\n",
      "F1 Score: 0.9983\n",
      "CNN_Credit saved at C:/Users/elbet/OneDrive/Desktop/Ten/week8&9/github/Fraud_detection/DL_saved_models\\CNN_Credit.pt\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Training RNN_Credit...\n",
      "Epoch [1/10], Loss: 0.0511\n",
      "Epoch [2/10], Loss: 0.0243\n",
      "Epoch [3/10], Loss: 0.0190\n",
      "Epoch [4/10], Loss: 0.0170\n",
      "Epoch [5/10], Loss: 0.0156\n",
      "Epoch [6/10], Loss: 0.0144\n",
      "Epoch [7/10], Loss: 0.0137\n",
      "Epoch [8/10], Loss: 0.0133\n",
      "Epoch [9/10], Loss: 0.0130\n",
      "Epoch [10/10], Loss: 0.0127\n",
      "Evaluating RNN_Credit...\n",
      "Accuracy: 0.9992\n",
      "Precision: 0.9993\n",
      "Recall: 0.9992\n",
      "F1 Score: 0.9992\n",
      "RNN_Credit saved at C:/Users/elbet/OneDrive/Desktop/Ten/week8&9/github/Fraud_detection/DL_saved_models\\RNN_Credit.pt\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Training LSTM_Credit...\n",
      "Epoch [1/10], Loss: 0.0334\n",
      "Epoch [2/10], Loss: 0.0078\n",
      "Epoch [3/10], Loss: 0.0045\n",
      "Epoch [4/10], Loss: 0.0028\n",
      "Epoch [5/10], Loss: 0.0019\n",
      "Epoch [6/10], Loss: 0.0015\n",
      "Epoch [7/10], Loss: 0.0012\n",
      "Epoch [8/10], Loss: 0.0010\n",
      "Epoch [9/10], Loss: 0.0009\n",
      "Epoch [10/10], Loss: 0.0008\n",
      "Evaluating LSTM_Credit...\n",
      "Accuracy: 0.9997\n",
      "Precision: 0.9997\n",
      "Recall: 0.9997\n",
      "F1 Score: 0.9997\n",
      "LSTM_Credit saved at C:/Users/elbet/OneDrive/Desktop/Ten/week8&9/github/Fraud_detection/DL_saved_models\\LSTM_Credit.pt\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Training and evaluating each model with MLflow tracking\n",
    "# Modify the existing model loop to include saving logic\n",
    "for model_name, model in models.items():\n",
    "    if isinstance(model, nn.Module):  # For PyTorch models\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        print(f\"\\nTraining {model_name}...\")\n",
    "        train_model(model, train_loader_fraud if \"Fraud\" in model_name else train_loader_credit, optimizer, criterion)\n",
    "        print(f\"Evaluating {model_name}...\")\n",
    "        evaluate_model(model, test_loader_fraud if \"Fraud\" in model_name else test_loader_credit)\n",
    "        save_pytorch_model(model, model_name)  # Save PyTorch model\n",
    "        print('----------------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "    else:  \n",
    "        print(\"nothing to print\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Explanability using shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multi-Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elbet\\AppData\\Local\\Temp\\ipykernel_70556\\2991818032.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('C:/Users/elbet/OneDrive/Desktop/Ten/week8&9/github/Fraud_detection/DL_saved_models/MLP_Fraud.pt'))\n",
      "100%|██████████| 46752/46752 [3:27:07<00:00,  3.76it/s]        \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1150x660 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import shap\n",
    "import torch\n",
    "\n",
    "# Load the saved model weights from the .pt file\n",
    "model.load_state_dict(torch.load('C:/Users/elbet/OneDrive/Desktop/Ten/week8&9/github/Fraud_detection/DL_saved_models/MLP_Fraud.pt'))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Define a custom prediction function for SHAP\n",
    "def model_predict(input_numpy):\n",
    "    input_tensor = torch.tensor(input_numpy, dtype=torch.float32)  # Convert back to tensor\n",
    "    model.eval()  # Ensure the model is in evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient computation for inference\n",
    "        return model(input_tensor).detach().cpu().numpy()  # Return numpy predictions\n",
    "\n",
    "# Convert test tensor to numpy array\n",
    "X_fraud_test_numpy = X_fraud_test_tensor.numpy()\n",
    "\n",
    "# Select a subset of your test data for SHAP\n",
    "X_fraud_test_sample = X_fraud_test_numpy[:10]\n",
    "\n",
    "# Use KernelExplainer for SHAP values\n",
    "explainer = shap.KernelExplainer(model_predict, X_fraud_test_sample)\n",
    "\n",
    "# Compute SHAP values\n",
    "shap_values = explainer.shap_values(X_fraud_test_numpy)\n",
    "\n",
    "# Visualize SHAP values\n",
    "shap.summary_plot(shap_values, X_fraud_test_numpy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elbet\\AppData\\Local\\Temp\\ipykernel_70556\\3925450680.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('C:/Users/elbet/OneDrive/Desktop/Ten/week8&9/github/Fraud_detection/DL_saved_models/CNN_Fraud.pt'))\n",
      " 22%|██▏       | 10159/46752 [1:35:32<34:20:50,  3.38s/it]"
     ]
    }
   ],
   "source": [
    "model = cnn_model_fraud \n",
    "# Load the saved model weights from the .pt file\n",
    "model.load_state_dict(torch.load('C:/Users/elbet/OneDrive/Desktop/Ten/week8&9/github/Fraud_detection/DL_saved_models/CNN_Fraud.pt'))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Define a custom prediction function for SHAP\n",
    "def model_predict(input_numpy):\n",
    "    input_tensor = torch.tensor(input_numpy, dtype=torch.float32)  # Convert back to tensor\n",
    "    model.eval()  # Ensure the model is in evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient computation for inference\n",
    "        return model(input_tensor).detach().cpu().numpy()  # Return numpy predictions\n",
    "\n",
    "# Convert test tensor to numpy array\n",
    "X_fraud_test_numpy = X_fraud_test_tensor.numpy()\n",
    "\n",
    "# Select a subset of your test data for SHAP\n",
    "X_fraud_test_sample = X_fraud_test_numpy[:10]\n",
    "\n",
    "# Use KernelExplainer for SHAP values\n",
    "explainer = shap.KernelExplainer(model_predict, X_fraud_test_sample)\n",
    "\n",
    "# Compute SHAP values\n",
    "shap_values = explainer.shap_values(X_fraud_test_numpy)\n",
    "\n",
    "# Visualize SHAP values\n",
    "shap.summary_plot(shap_values, X_fraud_test_numpy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rnn_model_fraud \n",
    "# Load the saved model weights from the .pt file\n",
    "model.load_state_dict(torch.load('C:/Users/elbet/OneDrive/Desktop/Ten/week8&9/github/Fraud_detection/DL_saved_models/RNN_Fraud.pt'))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Define a custom prediction function for SHAP\n",
    "def model_predict(input_numpy):\n",
    "    input_tensor = torch.tensor(input_numpy, dtype=torch.float32)  # Convert back to tensor\n",
    "    model.eval()  # Ensure the model is in evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient computation for inference\n",
    "        return model(input_tensor).detach().cpu().numpy()  # Return numpy predictions\n",
    "\n",
    "# Convert test tensor to numpy array\n",
    "X_fraud_test_numpy = X_fraud_test_tensor.numpy()\n",
    "\n",
    "# Select a subset of your test data for SHAP\n",
    "X_fraud_test_sample = X_fraud_test_numpy[:10]\n",
    "\n",
    "# Use KernelExplainer for SHAP values\n",
    "explainer = shap.KernelExplainer(model_predict, X_fraud_test_sample)\n",
    "\n",
    "# Compute SHAP values\n",
    "shap_values = explainer.shap_values(X_fraud_test_numpy)\n",
    "\n",
    "# Visualize SHAP values\n",
    "shap.summary_plot(shap_values, X_fraud_test_numpy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lstm_model_fraud \n",
    "# Load the saved model weights from the .pt file\n",
    "model.load_state_dict(torch.load('C:/Users/elbet/OneDrive/Desktop/Ten/week8&9/github/Fraud_detection/DL_saved_models/LSTM_Fraud.pt'))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Define a custom prediction function for SHAP\n",
    "def model_predict(input_numpy):\n",
    "    input_tensor = torch.tensor(input_numpy, dtype=torch.float32)  # Convert back to tensor\n",
    "    model.eval()  # Ensure the model is in evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient computation for inference\n",
    "        return model(input_tensor).detach().cpu().numpy()  # Return numpy predictions\n",
    "\n",
    "# Convert test tensor to numpy array\n",
    "X_fraud_test_numpy = X_fraud_test_tensor.numpy()\n",
    "\n",
    "# Select a subset of your test data for SHAP\n",
    "X_fraud_test_sample = X_fraud_test_numpy[:10]\n",
    "\n",
    "# Use KernelExplainer for SHAP values\n",
    "explainer = shap.KernelExplainer(model_predict, X_fraud_test_sample)\n",
    "\n",
    "# Compute SHAP values\n",
    "shap_values = explainer.shap_values(X_fraud_test_numpy)\n",
    "\n",
    "# Visualize SHAP values\n",
    "shap.summary_plot(shap_values, X_fraud_test_numpy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jojo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
